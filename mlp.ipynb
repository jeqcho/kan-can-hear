{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "3e3cb01e-bb07-4258-a265-132fbbe9fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from efficient_kan import KAN\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f3d4919c-ebe7-4222-a300-d49a2ed16965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "class SoundMaker:\n",
    "    def __init__(self, head_radius, speed_of_sound=300, min_distance=5, max_distance=500):\n",
    "        self.head_radius = head_radius\n",
    "        self.speed_of_sound = speed_of_sound\n",
    "        self.min_distance = min_distance\n",
    "        self.max_distance = max_distance\n",
    "\n",
    "    def make_sound(self):\n",
    "        azimuth = random.uniform(0, 2 * math.pi)\n",
    "        distance = random.uniform(self.min_distance, self.max_distance)\n",
    "        y = distance * math.cos(azimuth)\n",
    "        x = math.sqrt(distance**2 - y**2) * (-1)**(azimuth > math.pi)\n",
    "        distance_left = math.sqrt(y**2+(x-self.head_radius)**2)\n",
    "        distance_right = math.sqrt(y**2+(x+self.head_radius)**2)\n",
    "        dt = (distance_left - distance_right)/self.speed_of_sound\n",
    "        return dt, distance, azimuth\n",
    "\n",
    "soundMaker = SoundMaker(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ea90db17-8d00-4ce1-a65b-e90a3b81fcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>distance</th>\n",
       "      <th>azimuth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000512</td>\n",
       "      <td>17.380324</td>\n",
       "      <td>4.017637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000658</td>\n",
       "      <td>115.489315</td>\n",
       "      <td>1.728060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000664</td>\n",
       "      <td>339.966246</td>\n",
       "      <td>4.627385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000418</td>\n",
       "      <td>48.034722</td>\n",
       "      <td>5.605730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000314</td>\n",
       "      <td>19.749624</td>\n",
       "      <td>2.651013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.000530</td>\n",
       "      <td>217.386830</td>\n",
       "      <td>5.364297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-0.000666</td>\n",
       "      <td>9.373110</td>\n",
       "      <td>1.617118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-0.000623</td>\n",
       "      <td>329.837623</td>\n",
       "      <td>1.205442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-0.000600</td>\n",
       "      <td>227.864762</td>\n",
       "      <td>2.021106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.000664</td>\n",
       "      <td>252.594855</td>\n",
       "      <td>4.629108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dt    distance   azimuth\n",
       "0     0.000512   17.380324  4.017637\n",
       "1    -0.000658  115.489315  1.728060\n",
       "2     0.000664  339.966246  4.627385\n",
       "3     0.000418   48.034722  5.605730\n",
       "4    -0.000314   19.749624  2.651013\n",
       "...        ...         ...       ...\n",
       "9995  0.000530  217.386830  5.364297\n",
       "9996 -0.000666    9.373110  1.617118\n",
       "9997 -0.000623  329.837623  1.205442\n",
       "9998 -0.000600  227.864762  2.021106\n",
       "9999  0.000664  252.594855  4.629108\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10000\n",
    "df = pd.DataFrame([soundMaker.make_sound() for i in range(n)],columns=[\"dt\",\"distance\",\"azimuth\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f92753fb-b484-4b03-97b0-6bb799e3e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scaler = StandardScaler()\n",
    "target_scaler = StandardScaler()\n",
    "inputs = input_scaler.fit_transform(df[['dt']])\n",
    "targets = target_scaler.fit_transform(df[['azimuth']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2300d0f5-0651-46a4-864c-ac7e509e515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_target, test_target = train_test_split(inputs, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "8fa254c5-e824-4c33-b798-d628a0d32541",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = torch.tensor(self.inputs[idx], dtype=torch.float32)\n",
    "        targets = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4da898f5-8bc8-4a10-821c-72c817d9d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your custom dataset\n",
    "train_dataset = CustomDataset(train_input, train_target)\n",
    "test_dataset = CustomDataset(test_input, test_target)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd2a033a-1c99-42ea-a358-71ff2a03f5d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMLP\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_size, hidden_size, output_size):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(MLP, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        nn.init.normal_(self.hidden1.weight, mean=0, std=0.01)\n",
    "        nn.init.normal_(self.hidden1.bias, mean=0, std=0.01)\n",
    "        nn.init.normal_(self.hidden2.weight, mean=0, std=0.01)\n",
    "        nn.init.normal_(self.hidden2.bias, mean=0, std=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = self.hidden2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8587143-2c8a-4f4e-aed8-0be4a077e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31213f58-8bb5-4189-a1b4-59bca5e704bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(input_size=1, hidden_size=4, output_size=1)\n",
    "kan = KAN([1, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed4054-1330-41cb-83c8-dfcb00d694cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, title=\"MLP\", epochs=5):\n",
    "    optimizer = optim.SGD(mlp.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    # optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    # Define learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "    train_loss_all = []\n",
    "    val_loss_all = []\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        train_loss = 0\n",
    "        train_num = 0\n",
    "        model.train()\n",
    "        with tqdm(train_loader) as pbar:\n",
    "            running_loss = 0.0\n",
    "            for input, target in pbar:\n",
    "                input = input.view(-1, 1).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(input)\n",
    "                loss = criterion(output, target.to(device))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()*input.size(0)\n",
    "                train_num += input.size(0)\n",
    "                pbar.set_postfix(lr=optimizer.param_groups[0]['lr'])\n",
    "        print('Epoch %d, Train loss: %.3f' % (epoch + 1, train_loss/train_num))\n",
    "        train_loss_all.append(train_loss/train_num)\n",
    "        pbar.set_postfix(loss=train_loss/train_num)\n",
    "    \n",
    "        # Validation\n",
    "        mlp.eval()\n",
    "        val_loss = 0\n",
    "        val_accuracy = 0\n",
    "        val_num = 0\n",
    "        with torch.no_grad():\n",
    "            for input, target in test_loader:\n",
    "                input = input.view(-1, 1).to(device)\n",
    "                output = model(input)\n",
    "                val_loss += criterion(output, target.to(device)).item()*input.size(0)\n",
    "                val_num += input.size(0)\n",
    "        val_loss_all.append(val_loss/val_num)\n",
    "        # val_accuracy /= len(valloader)\n",
    "    \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "    \n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}, Val Loss: {val_loss/val_num}\"\n",
    "        )\n",
    "    # Plot the loss values against the number of epochs\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(range(1, epoch + 2), train_loss_all, label='Train Loss')\n",
    "    ax.plot(range(1, epoch + 2), val_loss_all, label='Val Loss')\n",
    "    ax.set_title(f'Loss Curves {title}')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94721d3-f8f8-4225-ad12-e7733d751bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(mlp, \"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9a1ba6-abf3-435c-a195-2401015995e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m(kan, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKAN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train(kan, \"KAN\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8adc95-749e-4401-846f-96848ca6f706",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(mlp\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/mlp.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(kan\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/kan.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(mlp.state_dict(), \"./models/mlp.pth\")\n",
    "torch.save(kan.state_dict(), \"./models/kan.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b33a7364-2298-4cf7-8bf8-5923e61e00c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 21.1982],\n",
      "        [-21.2094]])\n",
      "tensor([[ 3.1310],\n",
      "        [-0.0041]])\n",
      "[[8.8394231 ]\n",
      " [3.14755325]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeqcho/miniconda3/envs/kanenv/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = [0.01, -0.01]\n",
    "    inputs = np.array([[x] for x in inputs])\n",
    "    inputs = input_scaler.transform(inputs)\n",
    "    inputs = torch.tensor(np.array(inputs),dtype=torch.float32)\n",
    "    print(inputs)\n",
    "    \n",
    "    preds = kan(inputs)\n",
    "    print(preds)\n",
    "    print(target_scaler.inverse_transform(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f068b-05a8-4eeb-bdd4-362b1d85fb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aee47a-bb10-4d1e-a4e0-c6c534425afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kanenv)",
   "language": "python",
   "name": "kanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
